{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16433ca9-aeed-46de-a809-d064d220a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81611a10-f177-418e-9aeb-6b234a59aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67d678e-0d10-49ce-bb57-73cf322de723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba28601d-7dcb-43f5-b27a-afab41c648cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0180e1-8b2a-492b-84d8-1ee169552f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kcmc\n",
    "from kcmc.estimators import confounding_robust_estimator, hajek, ipw\n",
    "from kcmc.data_binary import generate_data, evaluate_policy, estimate_p_t\n",
    "from kcmc.data_continuous import generate_data, evaluate_policy, estimate_p_t\n",
    "from kcmc.data_real import generate_data, estimate_p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0033471d-ef0d-4031-8c84-2735c2a09804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, T, X = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432aeba4-68a2-4651-8f54-8b7ba8de15c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c101fe-5c65-4a6e-abaa-df9bfbc89e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d992fa-e3aa-4508-9d51-b252770febfb",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7531e67c-a620-4d0d-9e72-a355130b601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os.path\n",
    "\n",
    "EXAMPLE_PARAMS = {\n",
    "    'D': 200,\n",
    "    'lambd': 1.5, \n",
    "    'gamma': 0.01,\n",
    "    'alpha': 0.05,\n",
    "    'sigma2': 0.01,\n",
    "    'kernel': RBF(),\n",
    "    'hard_kernel_const': False,\n",
    "    'normalize_p_t': False,\n",
    "    'f_divergence': 'total variation', \n",
    "    'hajek_const': False,\n",
    "    'kernel_const': False,\n",
    "    'quantile_const': False,\n",
    "    'regressor_const': False,\n",
    "    'tan_box_const': False,\n",
    "    'lr_box_const': False,\n",
    "    'f_const': False,\n",
    "}\n",
    "\n",
    "def run_policy_evaluation_experiment(\n",
    "    log_file, params, policy, data_type='synthetic binary', sample_size=1000, n_seeds=1, seed0=0\n",
    "):\n",
    "    assert data_type in ['synthetic binary', 'synthetic continuous', 'real binary']\n",
    "    assert set(params.keys()) == set(EXAMPLE_PARAMS.keys())\n",
    "    for seed in range(seed0, seed0 + n_seeds):\n",
    "        Y, T, X, p_t = get_data(data_type, sample_size, seed)\n",
    "        try:\n",
    "            lower_bound = confounding_robust_estimator(Y, T, X, p_t, policy, **params).data.numpy()\n",
    "            upper_bound = -confounding_robust_estimator(-Y, T, X, p_t, policy, **params).data.numpy()\n",
    "        except:\n",
    "            print(f\"Encountered error for data_type={data_type}, sample_size={sample_size}, params={params}. Skipping the experiment.\")\n",
    "            continue\n",
    "        log_csv(log_file, data_type, policy.__name__, lower_bound, upper_bound, params, min(sample_size, T.shape[0]), seed)\n",
    "\n",
    "def get_data(data_type, sample_size, seed):\n",
    "    if 'synthetic' in data_type:\n",
    "        if 'binary' in data_type:\n",
    "            from kcmc.data_binary import generate_data, evaluate_policy, estimate_p_t\n",
    "        elif 'continuous' in data_type:\n",
    "            from kcmc.data_continuous import generate_data, evaluate_policy, estimate_p_t\n",
    "        else:\n",
    "            raise ValueError\n",
    "        np.random.seed(seed)\n",
    "        Y, T, X, U, e_x, e_xu = generate_data(sample_size)\n",
    "        p_t = estimate_p_t(X, T)\n",
    "    elif 'real' in data_type:\n",
    "        from kcmc.data_real import generate_data, estimate_p_t\n",
    "        Y, T, X = generate_data()\n",
    "        p_t = estimate_p_t(X, T)\n",
    "    return Y, T, X, p_t\n",
    "\n",
    "def log_csv(log_file, data_type, policy_name, lower_bound, upper_bound, params, sample_size, seed):\n",
    "    if not os.path.exists(log_file):\n",
    "        # make a column name\n",
    "        columns = ['data_type', 'policy_name', 'sample_size', 'seed', 'lower_bound', 'upper_bound', *params.keys()]\n",
    "        with open(log_file, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(columns)  \n",
    "    # log data by appending to the csv file\n",
    "    fields=[data_type, policy_name, sample_size, seed, lower_bound, upper_bound, *params.values()]\n",
    "    with open(log_file, 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffca407d-10ac-4f7c-80ba-c77fa9ff9158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kei/Desktop/env_pillbox/lib/python3.8/site-packages/statsmodels/base/model.py:2694: UserWarning: df_model + k_constant differs from nparams\n",
      "  warnings.warn(\"df_model + k_constant differs from nparams\")\n"
     ]
    }
   ],
   "source": [
    "log_file='logs/toy_experiments_log.csv'\n",
    "params = EXAMPLE_PARAMS.copy()\n",
    "#params['hajek_const'] = True\n",
    "#params['tan_box_const'] = True\n",
    "params['lr_box_const'] = True\n",
    "params['quantile_const'] = True\n",
    "params['kernel'] = RBF()\n",
    "run_policy_evaluation_experiment(log_file, params, toy_policy, data_type='synthetic continuous', n_seeds=1, sample_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93507ffa-b1ef-44a2-aee8-75507d28e66e",
   "metadata": {},
   "source": [
    "Notes on data types:\n",
    "\n",
    "- Only use torch tensor for `Y` and `r`\n",
    "- For other data, use numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4c07bec-f9ad-4714-b520-9a787113f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "np.random.seed(0)\n",
    "Y, T, X, U, e_x, e_xu = generate_data(n)\n",
    "p_t = estimate_p_t(X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7a9db7-2b67-419c-90bc-4f88614a44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y, T, X = generate_data()\n",
    "#p_t = estimate_p_t(X, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35928f1a-f708-4dfb-975f-9a13abb00a6c",
   "metadata": {},
   "source": [
    "### Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b0e38dd-c340-4ff0-9a77-62153a2c80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv   \n",
    "fields=['first','second','third']\n",
    "with open('experiments_log.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad6c1e-1f53-4c6c-9425-ccb87ab006d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eebe29d9-95b8-44b1-96e3-30164e9c2af5",
   "metadata": {},
   "source": [
    "### Define Toy Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14c0b72-5f51-4cfe-b369-81009ea78236",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_e_x = np.asarray([0, .75, -.5, 0, -1])\n",
    "\n",
    "def toy_policy(X, T):\n",
    "    n = X.shape[0]\n",
    "    T = torch.as_tensor(T)\n",
    "    z = torch.as_tensor(X) @ torch.as_tensor(beta_e_x)\n",
    "    e_x = torch.exp(z) / (1 + torch.exp(z))\n",
    "    return (1. - T) * e_x + T * (1. - e_x)\n",
    "\n",
    "# def zero_policy(X):\n",
    "#    return np.zeros(X.shape[0], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48942168-fbda-4bd8-8841-a3cf75af9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_continuous_policy(policy):\n",
    "    def wrapped_policy(X, T=None, return_sample=False, requires_grad=False): \n",
    "        policy_dist = policy(X)\n",
    "        if return_sample:\n",
    "            return policy_dist.rsample() if requires_grad else policy_dist.sample()\n",
    "        else:\n",
    "            return torch.exp(policy_dist.log_prob(torch.as_tensor(T)))\n",
    "    return wrapped_policy\n",
    "\n",
    "beta_e_x = np.asarray([0, .75, -.5, 0, -1])\n",
    "\n",
    "@wrap_continuous_policy\n",
    "def toy_policy(X):\n",
    "    z = torch.as_tensor(X) @ torch.as_tensor(beta_e_x)\n",
    "    mu_t = torch.exp(z) / (1 + torch.exp(z))\n",
    "    a, b = 3 * mu_t + 1, 3 * (1 - mu_t) + 1\n",
    "    return torch.distributions.beta.Beta(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ae6b5-a553-4938-b801-507577fbd957",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b93677-0b48-4c01-ac31-5d3512df0256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8210, dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(toy_policy, n=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192be7f4-218c-438b-936e-1fb36b12d858",
   "metadata": {
    "tags": []
   },
   "source": [
    "### IPW estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9122f446-64b0-4136-8e5e-f9a88dffbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_ipw = ipw(Y, T, X, p_t, toy_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "706245b2-acee-48fb-913c-0806dc1eddc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1126, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_ipw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b579c-ada1-43bb-8891-69257462c55a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hajek estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c618850-7e54-465a-b6a5-ca99df3785ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hajek = hajek(Y, T, X, p_t, toy_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd86c2c2-01da-4fca-b602-ba798e87bd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6988.2551, dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_hajek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850ff26-d019-4d86-bf76-b4cbef1cfc92",
   "metadata": {},
   "source": [
    "### Implement Confounding Robust Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f51fe24-3bd2-413c-b5b0-3082433d81f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KL',\n",
       " 'inverse KL',\n",
       " 'Jensen-Shannon',\n",
       " 'squared Hellinger',\n",
       " 'Pearson chi squared',\n",
       " 'Neyman chi squared',\n",
       " 'total variation']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcmc.estimators.f_divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee9afeb8-31cd-4924-8cad-37264ace3757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"est\" in \"estimator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a6345-79ce-4b0e-a8b9-7710bc687a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    hard_kernel_const=False,\n",
    "    f_divergence='total variation', \n",
    "    hajek_const=True,\n",
    "    kernel_const=False,\n",
    "    quantile_const=False,\n",
    "    tan_box_const=True,\n",
    "    lr_box_const=False,\n",
    "    f_const=False,\n",
    "    return_w=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c141267-1182-4a0b-8e50-f981432d52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76bf18-e762-4200-b0ea-391a8f8a9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hajek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0239b0-947c-46a3-a128-221d2b9b3f2c",
   "metadata": {},
   "source": [
    "#### Select Kernel for KCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1431c3b-104a-4550-8443-6661c619ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kei/Desktop/env_pillbox/lib/python3.8/site-packages/statsmodels/base/model.py:2694: UserWarning: df_model + k_constant differs from nparams\n",
      "  warnings.warn(\"df_model + k_constant differs from nparams\")\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "np.random.seed(0)\n",
    "Y, T, X, U, e_x, e_xu = generate_data(n)\n",
    "p_t = estimate_p_t(X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8705f-9baa-401d-852d-9d6b2a2b5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing kernel with approximate solution\n",
    "_, w_guess = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy, lambd=1.5,\n",
    "    hajek_const=True, tan_box_const=True, return_w=True,\n",
    ")\n",
    "e_guess = p_t * w_guess - 1\n",
    "gp_kernel = kcmc.estimators.fit_gp_kernel(e_guess, T, X)\n",
    "sigma2 = gp_kernel.k1.noise_level\n",
    "kernel = gp_kernel.k2\n",
    "\n",
    "est = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.5,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL', \n",
    "    hajek_const=False,\n",
    "    kernel_const=False,\n",
    "    quantile_const=False,\n",
    "    tan_box_const=False,\n",
    "    lr_box_const=False,\n",
    "    f_const=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809487d0-78fb-439c-8bae-13ffb94c6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff22bf-09d6-4b0f-840f-12f08d93c987",
   "metadata": {},
   "source": [
    "### Quantile Balancing with KernelPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f4c55-3653-4726-8cae-85b3e7913edb",
   "metadata": {},
   "source": [
    "est = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.5,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    f_divergence='KL', \n",
    "    hajek_const=False,\n",
    "    kernel_const=False,\n",
    "    quantile_const=True,\n",
    "    tan_box_const=True,\n",
    "    lr_box_const=False,\n",
    "    f_const=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a63b47-57b5-4766-9b08-8feaf9c4eb88",
   "metadata": {},
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2212dba1-8bb7-4d4a-a4e0-56a412d4a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing kernel with approximate solution\n",
    "_, w_guess = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5,\n",
    "    alpha=0.05,\n",
    "    sigma2=0.1,\n",
    "    kernel=RBF(),\n",
    "    hard_kernel_const=False,\n",
    "    kernel_const=True,\n",
    "    lr_box_const=True,\n",
    "    return_w=True,\n",
    ")\n",
    "e_guess = p_t * w_guess - 1\n",
    "gp_kernel = kcmc.estimators.fit_gp_kernel(e_guess, T, X)\n",
    "sigma2 = gp_kernel.k1.noise_level\n",
    "kernel = gp_kernel.k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa1d559e-186f-498d-afcc-591253d5e221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09932265319225153"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f97141f-34fd-4b87-8b6e-39b2904d1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.5,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=True,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=True,\n",
    "    quantile_const=False,\n",
    "    regressor_const=False,\n",
    "    lr_box_const=True,\n",
    "    f_const=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6706d7c4-b11b-4d0a-9717-6006061977ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7812, dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76e34e4a-2c94-4e2d-beb9-77146df64f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8054, dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f4b1f0-d176-4564-b52f-51dfc4735df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.5,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=False,\n",
    "    quantile_const=True,\n",
    "    lr_box_const=True,\n",
    "    f_const=False,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71759321-a7c8-45e6-8d51-7b18e0c4ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7142, dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08438b86-f006-4954-83c0-3cd6e11ee9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=50,\n",
    "    lambd=2.0, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=True,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=True,\n",
    "    quantile_const=True,\n",
    "    lr_box_const=True,\n",
    "    f_const=False,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "448aba57-a9ec-4a3a-bcba-0ac923b18990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5237, dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6a446a-4ec1-4ae7-8e99-4c62f486e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2=0.1 \n",
    "kernel=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4c4886d-6aac-4f06-bbd9-b20e0aba30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    hajek_const=False,\n",
    "    kernel_const=False,\n",
    "    quantile_const=True,\n",
    "    regressor_const=False,\n",
    "    lr_box_const=True,\n",
    "    f_const=False,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d6e62e7-356b-449e-91bd-56dfa99c9cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0735, dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab9c513d-aeed-4cc0-a537-277122e9f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=2.0, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=True,\n",
    "    quantile_const=False,\n",
    "    lr_box_const=True,\n",
    "    f_const=False,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7595c9ac-dfd7-4a79-8beb-24680271af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7427, dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e4eab14-e9e9-4a9a-b896-2e64b11636ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=True,\n",
    "    quantile_const=False,\n",
    "    lr_box_const=True,\n",
    "    f_const=True,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3a8bb6-598a-45fd-9047-237340ec77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6462, dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2aede4da-827a-43c0-8f35-d6a5cf33cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "est, w = confounding_robust_estimator(\n",
    "    Y, T, X, p_t, toy_policy,\n",
    "    D=200,\n",
    "    lambd=1.5, \n",
    "    gamma=0.01,\n",
    "    alpha=0.05,\n",
    "    sigma2=sigma2,\n",
    "    kernel=kernel,\n",
    "    hard_kernel_const=False,\n",
    "    normalize_p_t=False,\n",
    "    f_divergence='KL',\n",
    "    kernel_const=False, # doesn't have influence alone!\n",
    "    quantile_const=True,\n",
    "    lr_box_const=True,\n",
    "    f_const=True,\n",
    "    return_w=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08e802be-b0a0-429a-b0f6-840dd664c605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9044, dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a4f41c-977f-45fa-8214-252509e8344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_guess = w\n",
    "e_guess = p_t * w_guess - 1\n",
    "gp_kernel = kcmc.estimators.fit_gp_kernel(e_guess, T, X)\n",
    "sigma2 = gp_kernel.k1.noise_level\n",
    "kernel = gp_kernel.k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fed251-ac91-402e-8e58-512c0fd3bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16560784904777315"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058a91f-2c45-482c-90bf-360a10833ff5",
   "metadata": {},
   "source": [
    "### Compare Policy Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1e50f91-9bcb-4028-a87e-09e15de4d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_policy(X, T):\n",
    "    n = X.shape[0]\n",
    "    return 0.5 * torch.ones(n, dtype=float)\n",
    "\n",
    "def LR_policy(X, T, beta):\n",
    "    n = X.shape[0]\n",
    "    T = torch.as_tensor(T)\n",
    "    X = np.concatenate([np.ones([n, 1]), X], axis=1)\n",
    "    p = torch.sigmoid(torch.tensor(X) @ beta)\n",
    "    return (1 - T) * p + T * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c061b6-9fbd-4de8-96ac-ccee3fbfcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnPolicy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.nn[-2].weight.data[:] = 0.\n",
    "        self.nn[-2].bias.data[:] = 0.\n",
    "\n",
    "    def forward(self, X, T):\n",
    "        X = torch.as_tensor(X, dtype=torch.float32)\n",
    "        T = torch.as_tensor(T)\n",
    "        p = self.nn(X)[:, 0]\n",
    "        return (1 - T) * p + T * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d9f2a07-2a86-476e-a125-68f24426578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_continuous_policy\n",
    "def base_policy(X):\n",
    "    mu_t = 0.5 * torch.ones(X.shape[0])\n",
    "    a, b = 10 * mu_t + 1, 10 * (1 - mu_t) + 1\n",
    "    return torch.distributions.beta.Beta(a, b)\n",
    "\n",
    "def LR_policy(X, beta):\n",
    "    X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
    "    mu_t = torch.sigmoid(torch.tensor(X) @ beta)\n",
    "    a, b = 10 * mu_t + 1, 10 * (1 - mu_t) + 1\n",
    "    return torch.distributions.beta.Beta(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89f313ae-1040-4585-84d3-b5cc5328028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnPolicy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.nn[-2].weight.data[:] = 0.\n",
    "        self.nn[-2].bias.data[:] = 0.\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = torch.as_tensor(X, dtype=torch.float32)\n",
    "        mu_t = torch.sigmoid(self.nn(X)[:, 0])\n",
    "        a, b = 10 * mu_t + 1, 10 * (1 - mu_t) + 1\n",
    "        return torch.distributions.beta.Beta(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e15e5d7-d487-4bfa-a46b-3a6b77e2ec48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7413, dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(base_policy, n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6717fbcd-2256-4c46-9d0d-74413a230e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7534, dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_policy = wrap_continuous_policy(nnPolicy())\n",
    "evaluate_policy(nn_policy, n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7135e18-9fd9-4400-b83f-b1e4e7045ea5",
   "metadata": {},
   "source": [
    "#### Best Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72178905-238f-4688-b849-e5ddbc59f357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cdb7a3937241c2be40a915b0b5e81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_steps = 101\n",
    "beta_best = torch.zeros(6, requires_grad=True, dtype=float)\n",
    "best_policy = wrap_continuous_policy(lambda X: LR_policy(X, beta_best))\n",
    "optimizer = torch.optim.RMSprop(lr=1e-1, params=[beta_best])\n",
    "pbar = tqdm(range(train_steps))\n",
    "for i in pbar:\n",
    "    value = evaluate_policy(best_policy, n=100000, requires_grad=True)\n",
    "    (- value).backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    pbar.set_description(f\"Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65545b6-4bd4-474a-9f90-59e337d33998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 101\n",
    "beta_best = torch.zeros(6, requires_grad=True, dtype=float)\n",
    "best_policy = lambda X, T: LR_policy(X, T, beta_best)\n",
    "optimizer = torch.optim.RMSprop(lr=1e-1, params=[beta_best])\n",
    "pbar = tqdm(range(train_steps))\n",
    "for i in pbar:\n",
    "    value = evaluate_policy(best_policy, n=100000)\n",
    "    (- value).backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    pbar.set_description(f\"Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5860f1-5888-4134-809a-c6d88eaaee6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Just Run Hajek optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3faaf59a-d1e7-4e87-9b01-1b21de25ab0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faabfc98f47548d7a633195e1cb87812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_steps = 101\n",
    "beta_hajek = torch.zeros(6, requires_grad=True, dtype=float)\n",
    "hajek_policy = lambda X, T: LR_policy(X, T, beta_hajek)\n",
    "optimizer = torch.optim.RMSprop(lr=1e-1, params=[beta_hajek])\n",
    "pbar = tqdm(range(train_steps))\n",
    "for i in pbar:\n",
    "    value = hajek(Y, T, X, p_t, hajek_policy)\n",
    "    (- value).backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    pbar.set_description(f\"Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f68a7fc-d8b5-4677-a723-5f880e3643c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6822, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(hajek_policy, n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb89ee4-1cbf-4ce7-a209-c82e62340fd2",
   "metadata": {},
   "source": [
    "### Just run min-max optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0981074-6758-417c-9333-e230fea92029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confounding_robust_hajek(policy):\n",
    "    est = confounding_robust_estimator(\n",
    "        Y, T, X, p_t, policy, \n",
    "        lambd=1.5, hajek_const=True, tan_box_const=True,\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0de66b67-21ac-450f-94ba-3c712f171cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_confounding_robust_kernel(policy):\n",
    "    est = confounding_robust_estimator(\n",
    "        Y, T, X, p_t, policy, \n",
    "        D=200, lambd=1.5, alpha=0.05, \n",
    "        sigma2=sigma2, kernel=kernel,\n",
    "        kernel_const=True,\n",
    "        tan_box_const=True,\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d210ddd-d8e9-401a-900f-f7ec72c993e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4dc773be764029965dfc010d0887fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hajek policy min-max value\n",
    "train_steps = 101\n",
    "beta_hajek = torch.zeros(6, requires_grad=True, dtype=float)\n",
    "hajek_policy = lambda X, T: LR_policy(X, T, beta_hajek)\n",
    "optimizer = torch.optim.SGD(lr=1e-1, params=[beta_hajek])\n",
    "pbar = tqdm(range(train_steps))\n",
    "for i in pbar:\n",
    "    hajek_value = evaluate_confounding_robust_hajek(hajek_policy)\n",
    "    (- hajek_value).backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    pbar.set_description(f\"Value: {hajek_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13c26fa8-9f5b-40e9-9905-f8c71837e821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4034, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(hajek_policy, n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92634392-5a0d-45f6-897d-b689240d805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0741, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_confounding_robust_kernel(hajek_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3fdf7b7-97ce-4467-9245-5b7988855917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0d4bc381c54cc390a0da8a96a2ca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kernel policy min-max value\n",
    "train_steps = 101\n",
    "beta_kernel = torch.zeros(6, requires_grad=True, dtype=float)\n",
    "kernel_policy = lambda X, T: LR_policy(X, T, beta_kernel)\n",
    "optimizer = torch.optim.RMSprop(lr=1e-1, params=[beta_kernel])\n",
    "pbar = tqdm(range(train_steps))\n",
    "for i in pbar:\n",
    "    kernel_value = evaluate_confounding_robust_kernel(kernel_policy)\n",
    "    (- kernel_value).backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    pbar.set_description(f\"Value: {kernel_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4698840-9670-4345-8ed2-d63f69cde402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6240, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(kernel_policy, n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdb3ccc7-2906-4711-b340-2fda629f9840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4347, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_confounding_robust_kernel(kernel_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6681d-0cbc-498c-87fe-14518e3307d3",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- The difference in performance is sample-dependent\n",
    "  - If the sample is well confounded, then kernel + hajek tends to be better than hajek\n",
    "- IPW estimator is good enough in most cases, so we might not actually need confounding-robust methods\n",
    "- Still, kernel + hajek method offers better lower-bound of the policy value, so it must have some use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a7aee-64db-43bf-8f5f-c85431205461",
   "metadata": {},
   "source": [
    "### Make a Table for Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57708d10-0a72-4c40-93d3-a90ee6d52626",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi1 = lambda x: 0.5\n",
    "pi2 = toy_policy\n",
    "pi3 = best_policy\n",
    "pi4 = hajek_policy\n",
    "pi5 = kernel_policy\n",
    "pi6 = ipw_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07db702-4249-4340-abee-31a733991669",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "for i, pi in tqdm.tqdm(enumerate([pi1, pi2, pi3, pi4, pi5, pi6])):\n",
    "    table[f\"$\\\\pi_{i+1}$\"] = row = {}\n",
    "    row['$V_\\\\text{inf}$'] = float(evaluate_policy(pi, n=100000))\n",
    "    prob = pi(X) * torch.tensor(T) + (1 - pi(X)) * torch.tensor(1 - T)\n",
    "    r = torch.tensor(Y) * prob\n",
    "    row['$\\\\hat V_\\\\text{inf}^\\\\Hajek$'] = float(confoundingRobustHajek(r, T, a, b))\n",
    "    row['$\\\\hat V_\\\\text{inf}^\\\\kernel$'] = float(confoundingRobustKernel(r, T, X, a, b, p_t))\n",
    "    row['$\\\\hat V_\\\\text{inf}^\\\\text{IPW}$'] = float(IPW(r, p_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b99c09-4f54-4520-8475-3cd0350ffd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_copy = table.copy()\n",
    "table.pop(\"$\\\\pi_6$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43579457-5d7d-4556-9815-4333d60de3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\\\begin{tabular}{ | m{4em} || \" + \"m{3em} \" * len(table) + \"| }\")\n",
    "print(\"\\\\hline\")\n",
    "header = \"{}\\t\" + \"&{}\\t\" * len(table) + \"\\\\\\\\\"\n",
    "print(header.format(\"\", *table.keys()))\n",
    "print(\"\\\\hline\")\n",
    "\n",
    "row_names = table[\"$\\\\pi_1$\"].keys()\n",
    "for row in row_names:\n",
    "    s = \"{}\\t\" + \"&{:1.3f}\\t\" * len(table) + \"\\\\\\\\\"\n",
    "    print(s.format(row, *[col[row] for col in table.values()]))\n",
    "    print(\"\\\\hline\")\n",
    "print(\"\\\\end{tabular}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d4a48-9cf3-47c8-a017-367bd0cf22f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Estimate Propensity Score (Conditional Density Estimation)\n",
    "- This requires consistent nominal propensity score (p_obs(t|x))\n",
    "- For discrete t, just run kernel logistic regressionregret_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4e905-c91c-43c7-b967-cc7bcd7103b5",
   "metadata": {},
   "source": [
    "#### Discrete Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a554e-b59d-443c-940a-874042c719ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "# from sklearn.metrics import roc_auc_score, make_scorer\n",
    "# roc_auc_score = make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "model = LogisticRegressionCV().fit(X, T)\n",
    "e_xx = model.predict_proba(X)[:, 1]\n",
    "\n",
    "np.mean(np.abs(e_xx - e_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f90853-b1ba-4f3f-b164-8f0915553ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    gamma = trial.suggest_float('gamma', 1e-2, 1e+2, log=True)\n",
    "    lambd = trial.suggest_float('lambd', 1e-3, 1e+3, log=True)\n",
    "    model = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=100, kernel='rbf', gamma=gamma)),\n",
    "        ('LogReg', LogisticRegression(C=1/lambd)),\n",
    "    ])   \n",
    "    cv_scores = cross_val_score(model, X, y=T, cv=4)\n",
    "    return cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95449911-6b00-4578-b005-cdee0526b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(func=objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151c600-9947-43cb-abc1-6e0ce5955f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30624914-027f-4717-9b6b-b693bbf4c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = KernelPCA(n_components=200, kernel='rbf', gamma=0.01).fit_transform(X)\n",
    "model = LogisticRegression(C=5).fit(Z, T)\n",
    "e_xx = model.predict_proba(Z)[:, 1]\n",
    "\n",
    "np.mean(np.abs(e_xx - e_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b29946-0d5f-43af-ab66-08693ce19644",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(1 / e_x * T), np.mean(1 / (1 - e_x) * (1 - T)), # both should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a868d-77b7-4f17-ad20-f19fadc1313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(1 / e_xx * T), np.mean(1 / (1 - e_xx) * (1 - T)), # both should be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3f9c3-9589-42d7-b680-b3f5a2459f7d",
   "metadata": {},
   "source": [
    "#### Continuous Case (Maybe on the next notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52f0ef-5070-4431-aa95-d34d16532698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.kernel_density import KDEMultivariateConditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c75871-e5b0-4cf1-80a9-d71179e1e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "def benchmark_bandwidth(bw, T, X, cv=5):\n",
    "    n = T.shape[0]\n",
    "    indep_type='c' * X.shape[1]\n",
    "    dep_type='u'\n",
    "    split = (np.arange(n) % 5)\n",
    "    cross_entropy = 0\n",
    "    for i in range(cv):\n",
    "        train = (split != i)\n",
    "        test = (split == i)\n",
    "        model = KDEMultivariateConditional(T[train, None], X[train, :], dep_type='c', indep_type='c' * X.shape[1], bw=bw)\n",
    "        cross_entropy += np.mean(model.pdf(T[test, None], X[test, :]) + EPS) / cv\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601e3f6-4f21-4744-b52d-cff4ed8cf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scale = 0\n",
    "best_score = - float('inf')\n",
    "for scale in [0.1, 0.2, 0.3, 0.5, 0.7, 1, 1.5, 2, 3, 5]:\n",
    "    bw = scale * np.concatenate([[Y.std()], X.std(axis=0)]) / Y.shape[0] ** (1 / 7)\n",
    "    score = benchmark_bandwidth(bw, Y, X)\n",
    "    if score > best_score:\n",
    "        best_scale = scale\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb74c5-773c-4ba0-8562-d92ebee0bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scale, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a2066-614d-4390-bb2b-7730d19ce30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw0 = best_scale * np.concatenate([[Y.std()], X.std(axis=0)]) / Y.shape[0] ** (1 / 7)\n",
    "model = KDEMultivariateConditional(Y[:, None], X, dep_type='c', indep_type='c' * X.shape[1], bw=bw0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97445cb5-246d-458d-9faa-2af729248646",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_xx = model.pdf(Y[:, None], X)\n",
    "e_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc365b9-566e-4dfc-a52f-f9b29cd6a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(e_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23633bf1-ab0b-407c-8301-e8cac42995b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e5190-6262-4c27-8ccd-7a44587c0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(1. / e_xx * ((i <= Y) & (Y <= i + 1))) for i in range(7)]  # Should go to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e61f5-4574-4956-9d01-5c9bba9dd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't we use loo estimate for propensity? (For reducing the sampling bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c0419-f4b2-4446-ab71-5e6eee188523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loocv = KDEMultivariateConditional(Y[:500, None], X[:500], dep_type='c', indep_type='c' * X.shape[1], bw='cv_ml')\n",
    "model_loocv = KDEMultivariateConditional(Y[:, None], X, dep_type='c', indep_type='c' * X.shape[1], bw=model_loocv.bw)\n",
    "model_loocv.pdf(T[:, None], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95f284-4895-4f89-911f-a55ee335f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loocv.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207be7d-493b-4bb7-a554-d15aeeaff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_xx = model_loocv.pdf(Y[:, None], X)\n",
    "e_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00379916-a010-4344-acb0-ed140593554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(1. / e_xx * ((i <= Y) & (Y <= i + 1))) for i in range(7)]  # Should go to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63944a93-0dbd-48c3-90c2-36996d39e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, T, X, U, e_x, e_xu = generate_data(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd567f-84fa-49b6-b7da-35c624fab0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe better to use gaussian process regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, WhiteKernel, RBF\n",
    "from scipy.stats import norm\n",
    "\n",
    "kernel = WhiteKernel() + ConstantKernel() * RBF()\n",
    "model = GaussianProcessRegressor(kernel=kernel).fit(X, Y)\n",
    "mu, sigma = model.predict(X, return_std=True)\n",
    "e_xx = norm.pdf(Y, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81897c5-fc21-4a56-883c-5d5ec400d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(e_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a323a80-9992-431d-a38b-37ec4b41aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(1. / e_xx * ((i <= Y) & (Y <= i + 1))) for i in range(7)]  # Should go to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b6a80-fba6-4847-a569-c2314db4b076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
