{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f538a072-4655-4c9b-994f-0b85a62ad51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.linear_model import QuantileRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1d9e11-bee3-4f71-94e5-3c06e2d21882",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.random.randn(10)\n",
    "X = np.random.randn(10000 * 10).reshape(10000, 10)\n",
    "Y = X @ beta + np.random.randn(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eea4ae8-efd5-4542-a343-6053db19cec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros() received an invalid combination of arguments - got (int, type=type, requires_grad=bool), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mQuantileRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mQuantileRegressor.fit\u001b[0;34m(self, X, Y, n_iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(np\u001b[38;5;241m.\u001b[39mconcatenate([X, np\u001b[38;5;241m.\u001b[39mones((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      9\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile)\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (int, type=type, requires_grad=bool), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "QuantileRegressor(quantile=0.5, alpha=0.0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d3538f-2f2a-41c2-939b-de38a019f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.as_tensor(X)\n",
    "Yt = torch.as_tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "accbf3aa-f619-45ee-b474-48362e84617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hat = torch.tensor(np.zeros(10), requires_grad=True)\n",
    "beta0_hat = torch.tensor(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9bcfc52f-52fb-497a-9461-c3c643f0b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(error, q):\n",
    "    loss = q * torch.relu(error) + (1 - q) * torch.relu(-error)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "033e9211-6d31-4692-bb6f-707e8b371afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3301252a-3c1c-4b3e-9850-bc418234594e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1472, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_loss(Yt - Xt @ beta_hat - beta0_hat, 0.8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fdbf4953-43cb-4499-a7db-60412b9fca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = max(q, 1 - q)\n",
    "\n",
    "optim = torch.optim.SGD([beta_hat, beta0_hat], lr=1 / L)\n",
    "\n",
    "for i in range(20):\n",
    "    loss = quantile_loss(Yt - Xt @ beta_hat - beta0_hat, q).mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c105392c-1774-4b75-b07f-8275ca601182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2799, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "21e71c99-d7e1-4472-9529-8e27b576bde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1997)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Yt - Xt @ beta_hat - beta0_hat > 0).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2105a991-f529-4a0e-a159-c949d181af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileRegressor:\n",
    "    def __init__(self, quantile, alpha=None):\n",
    "        self.quantile = quantile\n",
    "\n",
    "    def fit(self, X, Y, n_iter=100):\n",
    "        self.dim = X.shape[1]\n",
    "        self.beta = torch.zeros(self.dim + 1, requires_grad=True, dtype=float)\n",
    "        X = torch.as_tensor(np.concatenate([X, np.ones((X.shape[0], 1))], axis=1))\n",
    "        L = max(self.quantile, 1 - self.quantile)\n",
    "        optim = torch.optim.SGD([self.beta], lr=0.3 / L)\n",
    "        for i in range(n_iter):\n",
    "            loss = self.quantile_loss(Y - X @ self.beta, self.quantile).mean()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = torch.as_tensor(np.concatenate([X, np.ones((X.shape[0], 1))], axis=1))\n",
    "        return X @ self.beta\n",
    "\n",
    "    @staticmethod\n",
    "    def quantile_loss(error, q):\n",
    "        loss = q * torch.relu(error) + (1 - q) * torch.relu(-error)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4d76406-5de6-4e7e-be6b-868141cc9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.as_tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0abfb68-e089-49a5-a77b-94d7f58eeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = QuantileRegressor(quantile=0.8, alpha=0.0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af165c78-74ca-43d6-912d-d9a869648c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y - m.predict(X) > 0).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990ba4e-da33-4ce6-9348-3dae70469c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395acfe-453b-4ee9-bcfb-83490fb29a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
