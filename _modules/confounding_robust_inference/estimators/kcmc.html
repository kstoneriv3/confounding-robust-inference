<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>confounding_robust_inference.estimators.kcmc &mdash; confounding-robust-inference 1.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=a56c686a"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            confounding-robust-inference
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/index.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/index.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">LICENSE</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">confounding-robust-inference</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">confounding_robust_inference.estimators.kcmc</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for confounding_robust_inference.estimators.kcmc</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Type</span>

<span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">ledoit_wolf</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">Kernel</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">torch.autograd.functional</span> <span class="kn">import</span> <span class="n">hessian</span><span class="p">,</span> <span class="n">jacobian</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span><span class="p">,</span> <span class="n">Optimizer</span>

<span class="kn">from</span> <span class="nn">confounding_robust_inference.estimators.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">BaseKCMCEstimator</span>
<span class="kn">from</span> <span class="nn">confounding_robust_inference.estimators.constraints</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_a_b</span><span class="p">,</span>
    <span class="n">get_box_constraints</span><span class="p">,</span>
    <span class="n">get_f_div_constraint</span><span class="p">,</span>
    <span class="n">get_gp_constraints</span><span class="p">,</span>
    <span class="n">get_kernel_constraints</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">confounding_robust_inference.estimators.misc</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CONSTRAINT_TYPES</span><span class="p">,</span>
    <span class="n">DEFAULT_KERNEL</span><span class="p">,</span>
    <span class="n">DUAL_FEASIBLE_CONSTRAINT_TYPES</span><span class="p">,</span>
    <span class="n">OrthogonalBasis</span><span class="p">,</span>
    <span class="n">assert_input</span><span class="p">,</span>
    <span class="n">get_dual_objective</span><span class="p">,</span>
    <span class="n">get_normal_ci</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">confounding_robust_inference.policies</span> <span class="kn">import</span> <span class="n">BasePolicy</span><span class="p">,</span> <span class="n">MixedPolicy</span>
<span class="kn">from</span> <span class="nn">confounding_robust_inference.utils.types</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_DEFAULT_TORCH_FLOAT_DTYPE</span><span class="p">,</span>
    <span class="n">as_ndarrays</span><span class="p">,</span>
    <span class="n">as_tensor</span><span class="p">,</span>
    <span class="n">as_tensors</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">WARNINGS_MODE</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="s2">&quot;module&quot;</span><span class="p">,</span> <span class="s2">&quot;once&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span>


<span class="k">def</span> <span class="nf">try_solvers</span><span class="p">(</span><span class="n">problem</span><span class="p">:</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">,</span> <span class="n">solvers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">installed_solvers</span> <span class="o">=</span> <span class="p">[</span><span class="n">sol</span> <span class="k">for</span> <span class="n">sol</span> <span class="ow">in</span> <span class="n">solvers</span> <span class="k">if</span> <span class="n">sol</span> <span class="ow">in</span> <span class="n">cp</span><span class="o">.</span><span class="n">installed_solvers</span><span class="p">()]</span>
    <span class="k">for</span> <span class="n">solver</span> <span class="ow">in</span> <span class="n">installed_solvers</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">problem</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">cp</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">SolverError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">if</span> <span class="n">problem</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;optimal&quot;</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="n">problem</span><span class="o">.</span><span class="n">status</span> <span class="o">!=</span> <span class="s2">&quot;optimal&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The optimizer found the associated convex programming to be </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">problem</span><span class="o">.</span><span class="n">status</span><span class="p">)</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">apply_black_magic</span><span class="p">(</span>
    <span class="n">Psi</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">p_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pi</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Black magic for choosing orthogonal basis.&quot;&quot;&quot;</span>
    <span class="c1"># Rescale the kernel per sample so that it&#39;s scale better matches that of Y</span>
    <span class="n">Psi</span> <span class="o">=</span> <span class="n">Psi</span> <span class="o">/</span> <span class="n">p_t</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">pi</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Psi</span> <span class="o">=</span> <span class="n">Psi</span> <span class="o">*</span> <span class="n">pi</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="c1"># constant basis is essential for numerical stability of f-divergence constraint</span>
    <span class="n">Psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">Psi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">p_t</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Do not rescale per basis here!!!</span>
    <span class="c1"># Otherwise, test data given to predict dual will be scaled differently.</span>
    <span class="c1"># Psi = Psi / np.linalg.norm(Psi, axis=0, keepdims=True)</span>
    <span class="k">return</span> <span class="n">Psi</span>


<div class="viewcode-block" id="KCMCEstimator">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator">[docs]</a>
<span class="k">class</span> <span class="nc">KCMCEstimator</span><span class="p">(</span><span class="n">BaseKCMCEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Kernel Conditional Moment Constraints (KCMC) Estimator by Ishikawa, He (2023).</span>

<span class="sd">    Args:</span>
<span class="sd">        const_type: Type of the constraint used. It must be one of &quot;Tan_box&quot;, &quot;lr_box&quot;, &quot;KL&quot;,</span>
<span class="sd">            &quot;inverse_KL&quot;, &quot;squared_Hellinger&quot;, &quot;Pearson_chi_squared&quot;,</span>
<span class="sd">            &quot;Neyman_chi_squared&quot;, and &quot;total_variation&quot;.</span>
<span class="sd">        gamma: Sensitivity parameter for f-divergence constraint satisfying gamma &gt;= 0.0.</span>
<span class="sd">            When gamma == 0.0, QB estimator is equivalent to the IPW estimator.</span>
<span class="sd">        Gamma: Sensitivity parameter for box constraints satisfying Gamma &gt;= 1.0.</span>
<span class="sd">            When Gamma == 1.0, QB estimator is equivalent to the IPW estimator.</span>
<span class="sd">        D: Dimension of the low-rank approximation used in the kernel quantile regression.</span>
<span class="sd">        kernel: Kernel used in the low-rank kernel quantile regression.</span>
<span class="sd">        rescale_by_policy_prob: Whether to rescale the kernel by policy probability $\pi(t|x)$.</span>
<span class="sd">            Rescaling by policy can help obtaining tighter lower bounds in some cases such as</span>
<span class="sd">            continuous treatment. Note that rescaling the kernel by the policy probability makes</span>
<span class="sd">            the lower bound non-differentiable so this option should not be used for gradient-based</span>
<span class="sd">            policy learning.  One should still be able to make it differentiable by replaceing</span>
<span class="sd">            cvxpy with cvxpylayers to make use of differentiable convex programming.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">const_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">Gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="n">Kernel</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">rescale_by_policy_prob</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">const_type</span> <span class="ow">in</span> <span class="n">CONSTRAINT_TYPES</span>
        <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="n">const_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Gamma</span> <span class="o">&gt;=</span> <span class="mi">1</span>
            <span class="c1"># For box constraint, it is convenient to assume gamma = 0.0, as eta_f -&gt; +0</span>
            <span class="c1"># in the dual problem.</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">gamma</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">=</span> <span class="n">const_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="k">if</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span> <span class="o">=</span> <span class="n">Gamma</span> <span class="k">if</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_by_policy_prob</span> <span class="o">=</span> <span class="n">rescale_by_policy_prob</span>

    <span class="k">def</span> <span class="nf">_warn_asymptotics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Current implementation of the asymptotics are known to be unstable, &quot;</span>
            <span class="s2">&quot;because of the difficulty of estimating the covariance and Hessian &quot;</span>
            <span class="s2">&quot;matrices involved. Please use the features with caution.&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="KCMCEstimator.fit_kpca">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.fit_kpca">[docs]</a>
    <span class="k">def</span> <span class="nf">fit_kpca</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KCMCEstimator</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit the kernel principal component analysis (KPCA) for the orthogonal function class.</span>

<span class="sd">        If this method is called before the :func:`fit` method, fit method will use the KPCA model</span>
<span class="sd">        fit by this method. Fitting KPCA with your validation data can be useful when you use</span>
<span class="sd">        different data for your :func:`fit` and :func:`predict_dual` methods.</span>

<span class="sd">        Args:</span>
<span class="sd">            T: Action variable (i.e. treatment).</span>
<span class="sd">            X: Context variable. Its dtype must be</span>
<span class="sd">                confounding_robust_inference.types._DEFAULT_TORCH_FLOAT_DTYPE.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_KERNEL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span> <span class="o">=</span> <span class="n">OrthogonalBasis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="KCMCEstimator.fit">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">BasePolicy</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">KCMCEstimator</span><span class="p">:</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span> <span class="o">=</span> <span class="n">p_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span>
        <span class="n">r_np</span><span class="p">,</span> <span class="n">Y_np</span><span class="p">,</span> <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

        <span class="c1"># concatenate T and X</span>
        <span class="c1"># TODO: need to handle the case when T is categorical by something like onehot encoding...</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Find orthognal function class</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;Psi_np_pipeline&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fit_kpca</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_by_policy_prob</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">Psi_np_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># TODO: replace w with w_tilde = p_t * w, for numerical stability</span>
        <span class="c1"># For avoiding user warning about multiplication operator with `*` and `@`</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">WARNINGS_MODE</span><span class="p">)</span>

            <span class="n">w</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

            <span class="n">objective</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">r_np</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>

            <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">Constraint</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">w</span><span class="p">]</span>
            <span class="n">kernel_consts</span> <span class="o">=</span> <span class="n">get_kernel_constraints</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">kernel_consts</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">:</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">get_box_constraints</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">f_div_const</span> <span class="o">=</span> <span class="n">get_f_div_constraint</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">)</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">f_div_const</span><span class="p">)</span>

            <span class="n">problem</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
            <span class="n">solvers</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">MOSEK</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">ECOS</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">SCS</span><span class="p">]</span>
            <span class="n">try_solvers</span><span class="p">(</span><span class="n">problem</span><span class="p">,</span> <span class="n">solvers</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_t</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">r</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span> <span class="o">=</span> <span class="n">problem</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span>
            <span class="o">-</span><span class="n">kernel_consts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dual_value</span> <span class="o">/</span> <span class="n">Psi_np_scale</span>
        <span class="p">)</span>  <span class="c1"># need to match sign!</span>
        <span class="c1"># For box constraints, the dual objective does not depend on eta_f so it does not matter.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">f_div_const</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dual_value</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="k">else</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="KCMCEstimator.predict">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span></div>


<div class="viewcode-block" id="KCMCEstimator.predict_dual">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.predict_dual">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_dual</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fitted_lower_bound&quot;</span><span class="p">)</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_by_policy_prob</span><span class="p">:</span>
            <span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">Psi</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">)</span>
        <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">Psi</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
        <span class="n">dual</span> <span class="o">=</span> <span class="n">get_dual_objective</span><span class="p">(</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">eta_cmc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dual</span></div>


<div class="viewcode-block" id="KCMCEstimator.predict_gic">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.predict_gic">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_gic</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate the Generalized Information Criterion (GIC) of the lower bound.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_warn_asymptotics</span><span class="p">()</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_loss_and_jacobian</span><span class="p">()</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">scores</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">J_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_hessian_inv</span><span class="p">()</span>  <span class="c1"># negative definite, as dual objective is concave</span>
        <span class="n">gic</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij, ji-&gt;&quot;</span><span class="p">,</span> <span class="n">J_inv</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">n</span>
        <span class="k">return</span> <span class="n">gic</span></div>


<div class="viewcode-block" id="KCMCEstimator.predict_ci">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.KCMCEstimator.predict_ci">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_ci</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="n">consider_second_order</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># n_mc: int = 2 ** 15,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate confidence interval of the lower bound.</span>

<span class="sd">        Args:</span>
<span class="sd">            alpha: Significance level of used for the confidence interval.</span>
<span class="sd">            consider_second_order: If True, consider the second order asymptotics similarly to GIC.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># &lt;- but ignore the variance of the second order term, which is O(d^2/n^2).</span>
        <span class="c1">#     When second order asymptotics is considered, Monte Carlo sampling is used for</span>
        <span class="c1">#     calculating the percentile of the asymptotic distribution.</span>
        <span class="c1"># n_mc: The number of Monte Carlo samples used to calculate the percentile of the</span>
        <span class="c1">#     asymptotic distribution.</span>
        <span class="k">if</span> <span class="n">consider_second_order</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_warn_asymptotics</span><span class="p">()</span>
            <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">lb_samples</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_loss_and_jacobian</span><span class="p">()</span>
            <span class="n">V</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">scores</span> <span class="o">/</span> <span class="n">n</span>
            <span class="n">J_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_hessian_inv</span><span class="p">()</span>  <span class="c1"># negative definite, as dual objective is concave</span>
            <span class="n">lb_samples</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij, ji-&gt;&quot;</span><span class="p">,</span> <span class="n">J_inv</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">n</span>
            <span class="c1"># mc_lb = self._monte_carlo_lower_bounds(n_mc)</span>
            <span class="c1"># low = torch.quantile(mc_lb, alpha / 2)</span>
            <span class="c1"># high = torch.quantile(mc_lb, 1 - alpha / 2)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lb_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">)</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">get_normal_ci</span><span class="p">(</span><span class="n">lb_samples</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span></div>


    <span class="k">def</span> <span class="nf">_monte_carlo_lower_bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_mc</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_loss_and_jacobian</span><span class="p">()</span>
        <span class="n">losses</span> <span class="o">-=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">l_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">losses</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">scores</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">V_joint</span> <span class="o">=</span> <span class="n">l_s</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">l_s</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">J_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dual_hessian_inv</span><span class="p">()</span>

        <span class="n">en</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quasirandom</span><span class="o">.</span><span class="n">SobolEngine</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scramble</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">unif_samples</span> <span class="o">=</span> <span class="n">en</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">n_mc</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">normal_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">icdf</span><span class="p">(</span><span class="n">unif_samples</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">mc_l_s</span> <span class="o">=</span> <span class="n">normal_samples</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">V_joint</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">mT</span>
        <span class="n">mc_l_s</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span>
        <span class="n">mc_losses</span><span class="p">,</span> <span class="n">mc_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">mc_l_s</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mc_lb</span> <span class="o">=</span> <span class="n">mc_losses</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;mi,ij,mj-&gt;m&quot;</span><span class="p">,</span> <span class="n">mc_scores</span><span class="p">,</span> <span class="n">J_inv</span><span class="p">,</span> <span class="n">mc_scores</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">mc_lb</span>

    <span class="k">def</span> <span class="nf">_get_fitted_dual_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eta</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># The dual objective does not depend on eta_f for box constraints</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;Tan_box&quot;</span><span class="p">,</span> <span class="s2">&quot;lr_box&quot;</span><span class="p">,</span> <span class="s2">&quot;total_variation&quot;</span><span class="p">):</span>
            <span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">eta</span>
            <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">:</span>
                <span class="n">eta_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">==</span> <span class="s2">&quot;total_variation&quot;</span><span class="p">:</span>
                <span class="c1"># The dual objective of the total variation can only be used evaluation,</span>
                <span class="c1"># and it is not differentiable.</span>
                <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fitted_lower_bound&quot;</span><span class="p">)</span>
                <span class="n">eta_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">eta</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">eta_f</span> <span class="o">=</span> <span class="n">eta</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">)</span> <span class="o">@</span> <span class="n">eta_kcmc</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">get_dual_objective</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span>
            <span class="n">eta_cmc</span><span class="p">,</span>
            <span class="n">eta_f</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">,</span>
        <span class="p">)</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        if not self.should_augment_data:</span>
<span class="sd">            &quot;&quot;&quot;</span>
<span class="sd">            should_augment_data: If True, use argumented data for estimation of hessian of the dual</span>
<span class="sd">                loss and asymptotic variance of its gradient. Empirically, this technique sometimes</span>
<span class="sd">                helps to stabilize the estimation of these quantities. For data augmentation, a</span>
<span class="sd">                kernel density estimator is used.</span>
<span class="sd">            &quot;&quot;&quot;</span>
<span class="sd">        else:</span>
<span class="sd">            # Argument data to get non-singular estimates of the Hessian and the Jacobian</span>
<span class="sd">            Y, T, X, p_t, pi = self.augment_data(3000)</span>
<span class="sd">            T_np, X_np, p_t_np = as_ndarrays(T, X, p_t)</span>
<span class="sd">            TX_np = np.concatenate([T_np[:, None], X_np], axis=1)</span>
<span class="sd">            Psi_np = self.Psi_np_pipeline.transform(TX_np)</span>
<span class="sd">            Psi_np = apply_black_magic(Psi_np, p_t_np, resacle=False)</span>
<span class="sd">            Psi = as_tensor(Psi_np)</span>
<span class="sd">            eta_cmc = Psi @ eta_kcmc</span>
<span class="sd">            loss = get_dual_objective(</span>
<span class="sd">                Y,</span>
<span class="sd">                p_t,</span>
<span class="sd">                pi,</span>
<span class="sd">                eta_cmc,</span>
<span class="sd">                eta_f,</span>
<span class="sd">                self.gamma,</span>
<span class="sd">                self.Gamma,</span>
<span class="sd">                self.const_type,</span>
<span class="sd">            )</span>
<span class="sd">            if torch.any(torch.isfinite(loss)):</span>
<span class="sd">                # Even if we select samples whose loss is not nan or infinite,</span>
<span class="sd">                # the backward pass tries to propagete zero grad for remaining samples,</span>
<span class="sd">                # resulting in nan gradients.</span>
<span class="sd">                mask = torch.isfinite(loss)</span>
<span class="sd">                loss = get_dual_objective(</span>
<span class="sd">                    Y[mask],</span>
<span class="sd">                    p_t[mask],</span>
<span class="sd">                    pi[mask],</span>
<span class="sd">                    eta_cmc[mask],</span>
<span class="sd">                    eta_f,</span>
<span class="sd">                    self.gamma,</span>
<span class="sd">                    self.Gamma,</span>
<span class="sd">                    self.const_type,</span>
<span class="sd">                )</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    # TODO: Unsupport this and support gic for subset of constraints.</span>
<span class="sd">    def augment_data(</span>
<span class="sd">        self, n: int, seed: int = 0</span>
<span class="sd">    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:</span>
<span class="sd">        Y_np, T_np, X_np, p_t_np = as_ndarrays(self.Y, self.T, self.X, self.p_t)</span>
<span class="sd">        log_p_t_np = np.log(p_t_np)</span>
<span class="sd">        T_unique, T_count = np.unique(T_np, return_counts=True)</span>
<span class="sd">        if len(T_unique) == len(T_np):  # T: continuous</span>
<span class="sd">            data = np.concatenate([Y_np[:, None], T_np[:, None], X_np, log_p_t_np[:, None]], axis=1)</span>
<span class="sd">            scaler = StandardScaler().fit(data)</span>
<span class="sd">            scaled_data = scaler.transform(data)</span>
<span class="sd">            scaled_augmented_data = gaussian_kde(scaled_data.T).resample(n, seed).T</span>
<span class="sd">            augmented_data = scaler.inverse_transform(scaled_augmented_data)</span>
<span class="sd">            Y_aug_np, T_aug_np, X_aug_np, log_p_t_aug_np = [</span>
<span class="sd">                (x[:, 0] if x.shape[1] == 1 else x)</span>
<span class="sd">                for x in np.split(augmented_data, [1, 2, -1], axis=1)</span>
<span class="sd">            ]</span>
<span class="sd">        else:</span>
<span class="sd">            data = np.concatenate([Y_np[:, None], X_np, log_p_t_np[:, None]], axis=1)</span>
<span class="sd">            T_prob = T_count / np.sum(T_count)</span>
<span class="sd">            T_aug_np = np.random.choice(T_unique, size=n, p=T_prob)</span>
<span class="sd">            augmented_data = np.empty((n, data.shape[1]))</span>
<span class="sd">            for i, t in enumerate(T_unique):</span>
<span class="sd">                n_t = sum(T_aug_np == t)</span>
<span class="sd">                data_t = data[T_np == t]</span>
<span class="sd">                scaler_t = StandardScaler().fit(data_t)</span>
<span class="sd">                scaled_data_t = scaler_t.transform(data_t)</span>
<span class="sd">                scaled_augmented_data_t = gaussian_kde(scaled_data_t.T).resample(n_t, seed).T</span>
<span class="sd">                augmented_data[T_aug_np == t] = scaler_t.inverse_transform(scaled_augmented_data_t)</span>
<span class="sd">            Y_aug_np, X_aug_np, log_p_t_aug_np = [</span>
<span class="sd">                (x[:, 0] if x.shape[1] == 1 else x)</span>
<span class="sd">                for x in np.split(augmented_data, [1, -1], axis=1)</span>
<span class="sd">            ]</span>
<span class="sd">            log_p_t_aug_np = np.minimum(</span>
<span class="sd">                0.0, log_p_t_aug_np</span>
<span class="sd">            )  # discrete probability mass must be &lt;= 1.</span>
<span class="sd">        p_t_aug_np = np.exp(log_p_t_aug_np)</span>
<span class="sd">        p_t_aug_np = np.clip(</span>
<span class="sd">            p_t_aug_np, 0.5 * min(p_t_np), 2 * max(p_t_np)</span>
<span class="sd">        )  # for numerical stability</span>
<span class="sd">        Y_arg, T_arg, X_arg, p_t_arg = as_tensors(Y_aug_np, T_aug_np, X_aug_np, p_t_aug_np)</span>
<span class="sd">        pi_arg = self.policy.prob(T_arg, X_arg)</span>
<span class="sd">        return Y_arg, T_arg, X_arg, p_t_arg, pi_arg</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">eta</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># The dual objective does not depend on eta_f for box constraints so ignore eta_f then.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;Tan_box&quot;</span><span class="p">,</span> <span class="s2">&quot;lr_box&quot;</span><span class="p">,</span> <span class="s2">&quot;total_variation&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span><span class="o">.</span><span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_get_dual_hessian_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;Tan_box&quot;</span><span class="p">,</span> <span class="s2">&quot;lr_box&quot;</span><span class="p">,</span> <span class="s2">&quot;total_variation&quot;</span><span class="p">):</span>
            <span class="c1"># Use numpy for computation in this block.</span>
            <span class="n">Y_np</span><span class="p">,</span> <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span><span class="p">,</span> <span class="n">eta_kcmc_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
            <span class="p">)</span>
            <span class="c1"># estimate p_{y|tx}(Pshi @ eta_kcmc)</span>
            <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">TX_np</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">DEFAULT_KERNEL</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">normalize_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">TX_np</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="p">(</span><span class="n">pi_np</span> <span class="o">*</span> <span class="n">Y_np</span><span class="p">)[:</span><span class="mi">1000</span><span class="p">])</span>
            <span class="n">r_mean</span><span class="p">,</span> <span class="n">r_std</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">TX_np</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">eta_cmc_mean</span><span class="p">,</span> <span class="n">eta_cmc_std</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="p">[</span><span class="n">r_mean</span><span class="p">,</span> <span class="n">r_std</span><span class="p">])</span>
            <span class="n">eta_cmc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">@</span> <span class="n">eta_kcmc_np</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">==</span> <span class="s2">&quot;total_variation&quot;</span><span class="p">:</span>
                <span class="n">conditional_pdf</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">eta_cmc</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">eta_cmc_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">eta_cmc_std</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">conditional_pdf</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;Tan_box&quot;</span><span class="p">,</span> <span class="s2">&quot;lr_box&quot;</span><span class="p">):</span>
                <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">get_a_b</span><span class="p">(</span><span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">)</span>
                <span class="n">conditional_pdf</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">eta_cmc</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">eta_cmc_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">eta_cmc_std</span><span class="p">)</span>
                <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p_t_np</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">conditional_pdf</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="kc">False</span>

            <span class="c1"># H = -as_tensor(</span>
            <span class="c1">#     self.Psi_np.T @ np.diag(scale ** 2) @ self.Psi_np / self.Psi_np.shape[0]</span>
            <span class="c1"># )</span>
            <span class="c1"># H_inv = torch.pinverse(H)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">*</span> <span class="n">scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="n">X_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">X_scale</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">X_cor</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ledoit_wolf</span><span class="p">(</span>
                <span class="n">X</span> <span class="o">/</span> <span class="n">X_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
            <span class="p">)</span>  <span class="c1"># A shrinkage estimator for stable estimation of covariance</span>
            <span class="n">X_cov</span> <span class="o">=</span> <span class="n">X_scale</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_cor</span> <span class="o">*</span> <span class="n">X_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">H_inv</span> <span class="o">=</span> <span class="o">-</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X_mean</span> <span class="o">*</span> <span class="n">X_mean</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">X_cov</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">==</span> <span class="s2">&quot;KL&quot;</span><span class="p">:</span>
            <span class="n">eta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">H</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="k">lambda</span> <span class="n">eta</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_fitted_dual_loss</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">eta</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
            <span class="n">H_inv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pinverse</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Estimation is very unstable or difficult due to non-differentiability.</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="k">return</span> <span class="n">H_inv</span>

    <span class="k">def</span> <span class="nf">_get_dual_loss_and_jacobian</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">one</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">one_and_eta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">one</span><span class="p">,</span> <span class="n">eta</span><span class="p">])</span>
        <span class="n">loss_and_J</span> <span class="o">=</span> <span class="n">jacobian</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_fitted_dual_loss</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">one_and_eta</span><span class="p">,</span>
            <span class="n">vectorize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_and_J</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">J</span> <span class="o">=</span> <span class="n">loss_and_J</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">J</span></div>



<div class="viewcode-block" id="DualKCMCEstimator">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCEstimator">[docs]</a>
<span class="k">class</span> <span class="nc">DualKCMCEstimator</span><span class="p">(</span><span class="n">BaseKCMCEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dual Kernel Conditional Moment Constraints (KCMC) Estimator trained by</span>
<span class="sd">    stochastic gradient descent.</span>

<span class="sd">    This estimator solves the dual problem of KCMC estimator using stochastic gradient descent</span>
<span class="sd">    (SGD). Though the quality of the solution is better when solving the primal problem by a convex</span>
<span class="sd">    optimization solver, SGD gives an advantage of scalability when the number of samples is large.</span>

<span class="sd">    Note:</span>
<span class="sd">        Though SGD is a widely-adopted means of solving this type of problem, we may be able to</span>
<span class="sd">        improve it by stochastic ADMM (Ouyang, He, et. al., 2013).</span>

<span class="sd">    Args:</span>
<span class="sd">        const_type: Type of the constraint used. It must be one of &quot;Tan_box&quot;, &quot;lr_box&quot;, &quot;KL&quot;,</span>
<span class="sd">            &quot;inverse_KL&quot;, &quot;Pearson_chi_squared&quot;.</span>
<span class="sd">        gamma: Sensitivity parameter for f-divergence constraint satisfying gamma &gt;= 0.0.</span>
<span class="sd">            When gamma == 0.0, QB estimator is equivalent to the IPW estimator.</span>
<span class="sd">        Gamma: Sensitivity parameter for box constraints satisfying Gamma &gt;= 1.0.</span>
<span class="sd">            When Gamma == 1.0, QB estimator is equivalent to the IPW estimator.</span>
<span class="sd">        D: Dimension of the low-rank approximation used in the kernel quantile regression.</span>
<span class="sd">        kernel: Kernel used in the low-rank kernel quantile regression.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">const_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">Gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="n">Kernel</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">const_type</span> <span class="ow">in</span> <span class="n">DUAL_FEASIBLE_CONSTRAINT_TYPES</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">const_type</span><span class="si">}</span><span class="s2"> is not supported.&quot;</span>
        <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="n">const_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Gamma</span> <span class="o">&gt;=</span> <span class="mi">1</span>
            <span class="c1"># For box constraint, it is convenient to assume gamma = 0.0, as eta_f -&gt; +0</span>
            <span class="c1"># in the dual problem.</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">gamma</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">=</span> <span class="n">const_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="k">if</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span> <span class="o">=</span> <span class="n">Gamma</span> <span class="k">if</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_DEFAULT_TORCH_FLOAT_DTYPE</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_eta_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_DEFAULT_TORCH_FLOAT_DTYPE</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="DualKCMCEstimator.fit">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCEstimator.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">BasePolicy</span><span class="p">,</span>
        <span class="n">optimizer_cls</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DualKCMCEstimator</span><span class="p">:</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span> <span class="o">=</span> <span class="n">p_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pi</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span>
        <span class="n">r_np</span><span class="p">,</span> <span class="n">Y_np</span><span class="p">,</span> <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_KERNEL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span> <span class="o">=</span> <span class="n">OrthogonalBasis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">Psi_np_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">3e-2</span><span class="p">,</span>
            <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_eta_f</span><span class="p">],</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">optimizer_kwargs</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">optimizer_kwargs</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
            <span class="n">train_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,))</span>
            <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])[</span><span class="n">train_idx</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="o">-</span><span class="n">get_dual_objective</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span>
                <span class="n">eta_cmc</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">objective</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">m</span> <span class="o">=</span> <span class="mi">1024</span>
        <span class="n">lower_bounds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">m</span><span class="p">):</span>
            <span class="n">val_idx</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])[</span><span class="n">val_idx</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
                <span class="n">lower_bounds</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_dual_objective</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pi</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span>
                    <span class="n">eta_cmc</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">lower_bounds</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">_DEFAULT_TORCH_FLOAT_DTYPE</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DualKCMCEstimator.predict">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCEstimator.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span></div>


<div class="viewcode-block" id="DualKCMCEstimator.predict_dual">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCEstimator.predict_dual">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_dual</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;fitted_lower_bound&quot;</span><span class="p">)</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
        <span class="n">dual</span> <span class="o">=</span> <span class="n">get_dual_objective</span><span class="p">(</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">eta_cmc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dual</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">eta_f</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_eta_f</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span></div>



<div class="viewcode-block" id="GPKCMCEstimator">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.GPKCMCEstimator">[docs]</a>
<span class="k">class</span> <span class="nc">GPKCMCEstimator</span><span class="p">(</span><span class="n">BaseKCMCEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gaussian Process Kernel Conditional Moment Constraints (GP-KCMC) Estimator</span>
<span class="sd">    by Ishikawa, He (2023).</span>

<span class="sd">    Args:</span>
<span class="sd">        const_type: Type of the constraint used. It must be one of &quot;box&quot;, &quot;KL&quot;, &quot;inverse_KL&quot;,</span>
<span class="sd">            &quot;squared_Hellinger&quot;, &quot;Pearson_chi_squared&quot;, &quot;Neyman_chi_squared&quot;, and</span>
<span class="sd">            &quot;total_variation&quot;.</span>
<span class="sd">        gamma: Sensitivity parameter for f-divergence constraint satisfying gamma &gt;= 0.0.</span>
<span class="sd">            When gamma == 0.0, GP-KCMC estimator is equivalent to the IPW estimator.</span>
<span class="sd">        Gamma: Sensitivity parameter for box constraints satisfying Gamma &gt;= 1.0.</span>
<span class="sd">            When Gamma == 1.0, GP-KCMC estimator is equivalent to the IPW estimator.</span>
<span class="sd">        D: Dimension of the low-rank approximation used in the kernel quantile regression.</span>
<span class="sd">        alpha: (Bayesian) Significance level of credible interval.</span>
<span class="sd">        sigma2: Noise level if the GP model.</span>
<span class="sd">        kernel: Kernel used by Gaussian process.</span>


<span class="sd">    Here, as low-rank GP is equivalent to Bayesian ridge regression with design matrix</span>
<span class="sd">    :math:`\\Psi_{n,d}=\\psi_d(t_n, x_n)`. Thus, we use the following model with</span>
<span class="sd">    :math:`\\sigma^2` estimated by empirical Bayes as</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \\begin{eqnarray}</span>
<span class="sd">          \\beta &amp;\\sim N(0, I_d), \\\\</span>
<span class="sd">          e &amp;= \\Psi \\beta + \\varepsilon, \\\\</span>
<span class="sd">          \\varepsilon &amp;\\sim N(0, \\sigma^2 I_n). \\\\</span>
<span class="sd">       \\end{eqnarray}</span>

<span class="sd">    For this model, the posterior and the credible set (highest posterior density set) of</span>
<span class="sd">    :math:`\\beta` are</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \\begin{eqnarray}</span>
<span class="sd">          \\beta | e &amp;\\sim N(\\mu_{\\beta|e}, \\Sigma_{\\beta|e})  \\\\</span>
<span class="sd">       \\end{eqnarray}</span>

<span class="sd">    and</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \\begin{eqnarray}</span>
<span class="sd">          \\mathrm{CI}_{\\beta|e}(1 - \\alpha) =</span>
<span class="sd">          \\{\\beta:</span>
<span class="sd">              (\\beta - \\mu_{\\beta|e})^T \\Sigma_{\\beta|e}^{-1} (\\beta - \\mu_{\\beta|e})</span>
<span class="sd">              \\leq \\chi^2_d(1 - \\alpha)</span>
<span class="sd">          \\},</span>
<span class="sd">       \\end{eqnarray}</span>

<span class="sd">    where :math:`\\mu_\\beta=(\\Psi^T\\Psi+\\sigma^2I_d)^{-1}\\Psi^Te`</span>
<span class="sd">    and :math:`\\Sigma_\\beta=(\\Psi^T\\Psi+\\sigma^2I_d)^{-1}`. Therefore, the condition </span>
<span class="sd">    :math:`0_d\\in \\mathrm{CI}_{\\beta|e}(1 - \\alpha)` can be written as</span>

<span class="sd">    .. math::</span>
<span class="sd">       :nowrap:</span>

<span class="sd">       \\begin{equation}</span>
<span class="sd">          \\mu_{\\beta|e}^T \\Sigma_{\\beta|e}^{-1} \\mu_{\\beta|e}</span>
<span class="sd">          = e^T \\Psi (\\Psi^T\\Psi + \\sigma^2I_d)^{-1} \\Psi^Te</span>
<span class="sd">          \\leq \\chi^2_d(1 - \\alpha).</span>
<span class="sd">       \\end{equation}</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">const_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">Gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span>
        <span class="n">sigma2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="n">Kernel</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">const_type</span> <span class="ow">in</span> <span class="n">CONSTRAINT_TYPES</span>
        <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="n">const_type</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Gamma</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">gamma</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="n">sigma2</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">=</span> <span class="n">const_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span> <span class="k">if</span> <span class="n">gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span> <span class="o">=</span> <span class="n">Gamma</span> <span class="k">if</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span> <span class="o">=</span> <span class="n">sigma2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span> <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_KERNEL</span>

<div class="viewcode-block" id="GPKCMCEstimator.fit">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.GPKCMCEstimator.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">policy</span><span class="p">:</span> <span class="n">BasePolicy</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GPKCMCEstimator</span><span class="p">:</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span> <span class="o">=</span> <span class="n">p_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>

        <span class="n">n</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">*</span> <span class="n">pi</span>
        <span class="n">r_np</span><span class="p">,</span> <span class="n">Y_np</span><span class="p">,</span> <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="n">pi</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span> <span class="o">=</span> <span class="n">OrthogonalBasis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">Psi_np_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># For avoiding user warning about multiplication operator with `*` and `@`</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">WARNINGS_MODE</span><span class="p">)</span>

            <span class="n">w</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

            <span class="n">objective</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">r_np</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">w</span><span class="p">)</span>

            <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">Constraint</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">w</span><span class="p">]</span>
            <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="n">get_gp_constraints</span><span class="p">(</span>
                    <span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;box&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">:</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">get_box_constraints</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">constraints</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">get_f_div_constraint</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">))</span>

            <span class="n">problem</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
            <span class="n">solvers</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">MOSEK</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">ECOS</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">SCS</span><span class="p">]</span>
            <span class="n">try_solvers</span><span class="p">(</span><span class="n">problem</span><span class="p">,</span> <span class="n">solvers</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_t</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">r</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span> <span class="o">=</span> <span class="n">problem</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="GPKCMCEstimator.predict">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.GPKCMCEstimator.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted_lower_bound</span></div>


<div class="viewcode-block" id="GPKCMCEstimator.predict_dual">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.GPKCMCEstimator.predict_dual">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_dual</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
</div>



<div class="viewcode-block" id="DualKCMCPolicyLearner">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCPolicyLearner">[docs]</a>
<span class="k">class</span> <span class="nc">DualKCMCPolicyLearner</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dual Kernel Conditional Moment Constraints (KCMC) policy learner for mixed policy.</span>

<span class="sd">    Args:</span>
<span class="sd">        const_type: Type of the constraint used. It must be one of &quot;Tan_box&quot;, &quot;lr_box&quot;.</span>
<span class="sd">        Gamma: Sensitivity parameter for box constraints satisfying Gamma &gt;= 1.0.</span>
<span class="sd">            When Gamma == 1.0, QB estimator is equivalent to the IPW estimator.</span>
<span class="sd">        D: Dimension of the low-rank approximation used in the kernel quantile regression.</span>
<span class="sd">        kernel: Kernel used in the low-rank kernel quantile regression.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">const_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">Gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">D</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
        <span class="n">kernel</span><span class="p">:</span> <span class="n">Kernel</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">const_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;Tan_box&quot;</span><span class="p">,</span> <span class="s2">&quot;lr_box&quot;</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">const_type</span><span class="si">}</span><span class="s2"> is not supported.&quot;</span>
        <span class="k">assert</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Gamma</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="c1"># For box constraint, it is convenient to assume gamma = 0.0, as eta_f -&gt; +0</span>
        <span class="c1"># in the dual problem.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span> <span class="o">=</span> <span class="n">const_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span> <span class="o">=</span> <span class="n">Gamma</span> <span class="k">if</span> <span class="n">Gamma</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">D</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">D</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_DEFAULT_TORCH_FLOAT_DTYPE</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<div class="viewcode-block" id="DualKCMCPolicyLearner.fit">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCPolicyLearner.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">policies</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">BasePolicy</span><span class="p">],</span>  <span class="c1"># type: ignore[override]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DualKCMCPolicyLearner</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Learns the policy that maximizes the lower bound of the given data.</span>

<span class="sd">        Args:</span>
<span class="sd">            Y: Outcome variable. It must be a tensor of shape [n_samples] and type</span>
<span class="sd">                confounding_robust_inference.types._DEFAULT_TORCH_FLOAT_DTYPE.</span>
<span class="sd">            T: Action variable (i.e. treatment). It must be a tensor of shape [n_samples].</span>
<span class="sd">            X: Context variable. It must be a tensor of shape [n_samples, n_dim] and type</span>
<span class="sd">                confounding_robust_inference.types._DEFAULT_TORCH_FLOAT_DTYPE.</span>
<span class="sd">            p_t: Nominal propensity p_obs(t|x). It must be a tensor of shape [n_samples] and type</span>
<span class="sd">                confounding_robust_inference.types._DEFAULT_TORCH_FLOAT_DTYPE.</span>
<span class="sd">            policies: Policies whose mixture constitutes the policy space for the policy learning.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">policies</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">T</span> <span class="o">=</span> <span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span> <span class="o">=</span> <span class="n">p_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policies</span> <span class="o">=</span> <span class="n">policies</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pi_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">policy</span> <span class="ow">in</span> <span class="n">policies</span><span class="p">]</span>

        <span class="n">Y_np</span><span class="p">,</span> <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="o">*</span><span class="n">pi_np_list</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">pi_list</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_KERNEL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span> <span class="o">=</span> <span class="n">OrthogonalBasis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">Psi_np_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">a_w_tilde</span><span class="p">,</span> <span class="n">b_w_tilde</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_a_b_w_tilde</span><span class="p">(</span><span class="n">p_t</span><span class="p">)</span>
        <span class="n">a_w_tilde_np</span><span class="p">,</span> <span class="n">b_w_tilde_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">a_w_tilde</span><span class="p">,</span> <span class="n">b_w_tilde</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f_conj_cp</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">cp</span><span class="o">.</span><span class="n">Expression</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">cp</span><span class="o">.</span><span class="n">Expression</span><span class="p">:</span>
            <span class="c1"># operator * is dot product in cvxpy</span>
            <span class="k">return</span> <span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">b_w_tilde_np</span> <span class="o">-</span> <span class="n">a_w_tilde_np</span><span class="p">),</span> <span class="n">cp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="o">+</span> <span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span>
                <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">b_w_tilde_np</span> <span class="o">+</span> <span class="n">a_w_tilde_np</span><span class="p">),</span> <span class="n">v</span>
            <span class="p">)</span>

        <span class="c1"># For avoiding user warning about multiplication operator with `*` and `@`</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">WARNINGS_MODE</span><span class="p">)</span>

            <span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">policies</span><span class="p">))</span>

            <span class="n">eta_cmc</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
            <span class="p">)</span> <span class="o">@</span> <span class="n">eta_kcmc</span>  <span class="c1"># This is still a matrix multiplication</span>
            <span class="n">pi_cp</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">b</span> <span class="o">*</span> <span class="n">pi_np</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">pi_np</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">pi_np_list</span><span class="p">)])</span>
            <span class="n">dual</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">eta_cmc</span> <span class="o">-</span> <span class="n">f_conj_cp</span><span class="p">(</span><span class="n">eta_cmc</span> <span class="o">-</span> <span class="n">cp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">Y_np</span> <span class="o">/</span> <span class="n">p_t_np</span><span class="p">,</span> <span class="n">pi_cp</span><span class="p">)))</span>

            <span class="n">objective</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Maximize</span><span class="p">(</span><span class="n">dual</span><span class="p">)</span>
            <span class="n">constraints</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">Constraint</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">policies</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="n">beta</span><span class="p">,</span>
                <span class="n">cp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">problem</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
            <span class="n">solvers</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp</span><span class="o">.</span><span class="n">MOSEK</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">ECOS</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">SCS</span><span class="p">]</span>
            <span class="n">try_solvers</span><span class="p">(</span><span class="n">problem</span><span class="p">,</span> <span class="n">solvers</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_t</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">eta_kcmc</span><span class="o">.</span><span class="n">value</span> <span class="o">/</span> <span class="n">Psi_np_scale</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">p_t</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">policies</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="DualKCMCPolicyLearner.predict">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCPolicyLearner.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">predict_dual</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">assert_input</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="n">T_np</span><span class="p">,</span> <span class="n">X_np</span><span class="p">,</span> <span class="n">p_t_np</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="n">TX_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">T_np</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">X_np</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">Psi_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Psi_np_pipeline</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">TX_np</span><span class="p">)</span>
        <span class="n">Psi_np</span> <span class="o">=</span> <span class="n">apply_black_magic</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">,</span> <span class="n">p_t_np</span><span class="p">)</span>
        <span class="n">eta_cmc</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">Psi_np</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta_kcmc</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">b</span> <span class="o">*</span> <span class="n">policy</span><span class="o">.</span><span class="n">prob</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">policy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">policies</span><span class="p">)]),</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># mixed policy prob</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dual_objective</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">p_t</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">eta_cmc</span><span class="p">)</span>

<div class="viewcode-block" id="DualKCMCPolicyLearner.predict_ci">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCPolicyLearner.predict_ci">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_ci</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate confidence interval of the lower bound.</span>

<span class="sd">        Args:</span>
<span class="sd">            alpha: Significance level of used for the confidence interval.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lb_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_dual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_t</span><span class="p">)</span>
        <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="n">get_normal_ci</span><span class="p">(</span><span class="n">lb_samples</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">low</span><span class="p">,</span> <span class="n">high</span></div>


<div class="viewcode-block" id="DualKCMCPolicyLearner.predict_policy">
<a class="viewcode-back" href="../../../api_reference/estimators.html#confounding_robust_inference.estimators.DualKCMCPolicyLearner.predict_policy">[docs]</a>
    <span class="k">def</span> <span class="nf">predict_policy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MixedPolicy</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the learned optimal policy.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">MixedPolicy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policies</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">dual_objective</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pi</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">eta_cmc</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">a_w_tilde</span><span class="p">,</span> <span class="n">b_w_tilde</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_a_b_w_tilde</span><span class="p">(</span><span class="n">p_t</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">f_conj</span><span class="p">(</span><span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">v</span> <span class="o">&lt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">a_w_tilde</span> <span class="o">*</span> <span class="n">v</span><span class="p">,</span> <span class="n">b_w_tilde</span> <span class="o">*</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">dual</span> <span class="o">=</span> <span class="n">eta_cmc</span> <span class="o">-</span> <span class="n">f_conj</span><span class="p">(</span><span class="n">eta_cmc</span> <span class="o">-</span> <span class="n">Y</span> <span class="o">*</span> <span class="n">pi</span> <span class="o">/</span> <span class="n">p_t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dual</span>

    <span class="k">def</span> <span class="nf">get_a_b_w_tilde</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="p">(</span><span class="n">p_t_np</span><span class="p">,)</span> <span class="o">=</span> <span class="n">as_ndarrays</span><span class="p">(</span><span class="n">p_t</span><span class="p">)</span>
        <span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span> <span class="o">=</span> <span class="n">get_a_b</span><span class="p">(</span><span class="n">p_t_np</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">const_type</span><span class="p">)</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">as_tensors</span><span class="p">(</span><span class="n">a_np</span><span class="p">,</span> <span class="n">b_np</span><span class="p">)</span>
        <span class="n">a_w_tilde</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">p_t</span>
        <span class="n">b_w_tilde</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">p_t</span>
        <span class="k">return</span> <span class="n">a_w_tilde</span><span class="p">,</span> <span class="n">b_w_tilde</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Kei Ishikawa.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>